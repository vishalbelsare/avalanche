:mod:`avalanche.evaluation.metrics.cpu_usage`
=============================================

.. py:module:: avalanche.evaluation.metrics.cpu_usage


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.cpu_usage.CPUUsage
   avalanche.evaluation.metrics.cpu_usage.MinibatchCPUUsage
   avalanche.evaluation.metrics.cpu_usage.EpochCPUUsage
   avalanche.evaluation.metrics.cpu_usage.RunningEpochCPUUsage
   avalanche.evaluation.metrics.cpu_usage.ExperienceCPUUsage
   avalanche.evaluation.metrics.cpu_usage.StreamCPUUsage



Functions
~~~~~~~~~

.. autoapisummary::

   avalanche.evaluation.metrics.cpu_usage.cpu_usage_metrics


.. py:class:: CPUUsage

   Bases: :class:`Metric[float]`

   The standalone CPU usage metric.

   Instances of this metric compute the average CPU usage as a float value.
   The metric starts tracking the CPU usage when the `update` method is called
   for the first time. That is, the tracking does not start at the time the
   constructor is invoked.

   Calling the `update` method more than twice will update the metric to the
   average usage between the first and the last call to `update`.

   The result, obtained using the `result` method, is the usage computed
   as stated above.

   The reset method will bring the metric to its initial state. By default
   this metric in its initial state will return an usage value of 0.

   Creates an instance of the standalone CPU usage metric.

   By default this metric in its initial state will return a CPU usage
   value of 0. The metric can be updated by using the `update` method
   while the average CPU usage can be retrieved using the `result` method.

   .. attribute:: _mean_usage
      

      The mean utility that will be used to store the average usage.


   .. attribute:: _process_handle
      :annotation: :Optional[Process]

      The process handle, lazily initialized.


   .. attribute:: _first_update
      :annotation: = True

      An internal flag to keep track of the first call to the `update` method.


   .. method:: update(self) -> None

      Update the running CPU usage.

      For more info on how to set the starting moment see the class
      description.

      :return: None.


   .. method:: result(self) -> float

      Retrieves the average CPU usage.

      Calling this method will not change the internal state of the metric.

      :return: The average CPU usage, as a float value.


   .. method:: reset(self) -> None

      Resets the metric.

      :return: None.



.. py:class:: MinibatchCPUUsage

   Bases: :class:`PluginMetric[float]`

   The minibatch CPU usage metric.
   This plugin metric only works at training time.

   This metric "logs" the CPU usage for each iteration.

   If a more coarse-grained logging is needed, consider using
   :class:`EpochCPUUsage`.

   Creates an instance of the minibatch CPU usage metric.

   .. method:: result(self) -> float


   .. method:: reset(self) -> None


   .. method:: before_training_iteration(self, strategy) -> MetricResult


   .. method:: after_training_iteration(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: EpochCPUUsage

   Bases: :class:`PluginMetric[float]`

   The Epoch CPU usage metric.
   This plugin metric only works at training time.

   The average usage will be logged after each epoch.

   Creates an instance of the epoch CPU usage metric.

   .. method:: before_training_epoch(self, strategy) -> MetricResult


   .. method:: after_training_epoch(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: RunningEpochCPUUsage

   Bases: :class:`PluginMetric[float]`

   The running epoch CPU usage metric.
   This plugin metric only works at training time

   After each iteration, the metric logs the average CPU usage up
   to the current epoch iteration.

   Creates an instance of the average epoch cpu usage metric.

   .. method:: before_training_epoch(self, strategy) -> MetricResult


   .. method:: before_training_iteration(self, strategy: PluggableStrategy) -> 'MetricResult'


   .. method:: after_training_iteration(self, strategy: PluggableStrategy) -> None


   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: ExperienceCPUUsage

   Bases: :class:`PluginMetric[float]`

   The average experience CPU usage metric.
   This plugin metric works only at eval time.

   After each experience, this metric emits the average CPU usage on that
   experienc.

   Creates an instance of the experience CPU usage metric.

   .. method:: before_eval_exp(self, strategy: PluggableStrategy) -> None


   .. method:: after_eval_exp(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. py:class:: StreamCPUUsage

   Bases: :class:`PluginMetric[float]`

   The average stream CPU usage metric.
   This plugin metric works only at eval time.

   After the entire evaluation stream, this metric emits
   the average CPU usage on all experiences.

   Creates an instance of the stream CPU usage metric.

   .. method:: before_eval(self, strategy: PluggableStrategy) -> None


   .. method:: after_eval(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: reset(self) -> None


   .. method:: result(self) -> float


   .. method:: _package_result(self, strategy: PluggableStrategy) -> MetricResult


   .. method:: __str__(self)

      Return str(self).



.. function:: cpu_usage_metrics(*, minibatch=False, epoch=False, epoch_running=False, experience=False, stream=False) -> List[PluginMetric]

   Helper method that can be used to obtain the desired set of
   plugin metrics.

   :param minibatch: If True, will return a metric able to log the minibatch
       CPU usage
   :param epoch: If True, will return a metric able to log the epoch
       CPU usage
   :param epoch_running: If True, will return a metric able to log the running
       epoch CPU usage.
   :param experience: If True, will return a metric able to log the experience
       CPU usage.
   :param stream: If True, will return a metric able to log the evaluation
       stream CPU usage.

   :return: A list of plugin metrics.


