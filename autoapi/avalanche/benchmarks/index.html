

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>avalanche.benchmarks &mdash; Avalanche 0.1 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/mystyle.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/graphviz.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex/" />
    <link rel="search" title="Search" href="../../../search/" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../">
          

          
            
            <img src="../../../_static/avalanche_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Avalanche API:</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="../../">API Reference</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="../"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche</span></code></a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4 current"><a class="current reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../evaluation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.evaluation</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../logging/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.logging</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../models/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.models</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="../training/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.training</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../#submodules">Submodules</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../core/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.core</span></code></a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../#package-contents">Package Contents</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../#functions">Functions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../">Avalanche</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../" class="icon icon-home"></a> &raquo;</li>
        
      <li><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../../../_sources/autoapi/avalanche/benchmarks/index.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-avalanche.benchmarks">
<span id="avalanche-benchmarks"></span><h1><a class="reference internal" href="#module-avalanche.benchmarks" title="avalanche.benchmarks"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks</span></code></a><a class="headerlink" href="#module-avalanche.benchmarks" title="Permalink to this headline">¶</a></h1>
<p>The <code class="xref py py-mod docutils literal notranslate"><span class="pre">benchmarks</span></code> module provides a set of utilities that can be used for
handling and generating your continual learning data stream. In the
<code class="xref py py-mod docutils literal notranslate"><span class="pre">datasets</span></code> module, basic PyTorch Datasets are provided. In the
<code class="xref py py-mod docutils literal notranslate"><span class="pre">classic</span></code> module instead, classic scenarios (already proposed in the
CL literature) generated from the datasets are provided. Finally,
in <code class="xref py py-mod docutils literal notranslate"><span class="pre">generators</span></code> basic utilities to generate new scenarios on-the-fly are
made available.</p>
<div class="section" id="subpackages">
<h2>Subpackages<a class="headerlink" href="#subpackages" title="Permalink to this headline">¶</a></h2>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="classic/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="classic/ccifar10/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.ccifar10</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/ccifar100/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.ccifar100</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/ccub200/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.ccub200</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/cfashion_mnist/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.cfashion_mnist</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/cimagenet/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.cimagenet</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/cmnist/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.cmnist</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/comniglot/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.comniglot</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/core50/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.core50</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/ctiny_imagenet/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.ctiny_imagenet</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/openloris/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.openloris</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="classic/stream51/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.classic.stream51</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="datasets/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="datasets/core50/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.core50</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/core50/core50/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.core50.core50</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/core50/core50_data/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.core50.core50_data</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets/cub200/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.cub200</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/cub200/cub200/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.cub200.cub200</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets/mini_imagenet/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.mini_imagenet</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/mini_imagenet/mini_imagenet/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.mini_imagenet.mini_imagenet</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/mini_imagenet/mini_imagenet_data/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.mini_imagenet.mini_imagenet_data</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets/openloris/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.openloris</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/openloris/openloris/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.openloris.openloris</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/openloris/openloris_data/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.openloris.openloris_data</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets/stream51/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.stream51</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/stream51/stream51/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.stream51.stream51</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="datasets/stream51/stream51_data/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.stream51.stream51_data</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets/tiny_imagenet/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.tiny_imagenet</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="datasets/tiny_imagenet/tiny_imagenet/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.tiny_imagenet.tiny_imagenet</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="datasets/imagenet_data/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.imagenet_data</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/omniglot/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.omniglot</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="datasets/torchvision_wrapper/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.datasets.torchvision_wrapper</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="generators/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="generators/scenario_generators/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators.scenario_generators</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="scenarios/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="scenarios/new_classes/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_classes</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="scenarios/new_classes/nc_scenario/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_classes.nc_scenario</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="scenarios/new_classes/nc_utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_classes.nc_utils</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="scenarios/new_instances/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_instances</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="scenarios/new_instances/ni_scenario/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_instances.ni_scenario</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="scenarios/new_instances/ni_utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.new_instances.ni_utils</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="scenarios/generic_cl_scenario/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_cl_scenario</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="scenarios/generic_definitions/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_definitions</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="scenarios/generic_scenario_creation/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.scenarios.generic_scenario_creation</span></code></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils</span></code></a><ul>
<li class="toctree-l2"><a class="reference internal" href="utils/avalanche_dataset/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.avalanche_dataset</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/data_loader/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.data_loader</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/dataset_definitions/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.dataset_definitions</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/dataset_utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.dataset_utils</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/datasets_from_filelists/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.datasets_from_filelists</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/torchvision_wrapper/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.torchvision_wrapper</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="utils/utils/"><code class="xref py py-mod docutils literal notranslate"><span class="pre">avalanche.benchmarks.utils.utils</span></code></a></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="package-contents">
<h2>Package Contents<a class="headerlink" href="#package-contents" title="Permalink to this headline">¶</a></h2>
<div class="section" id="classes">
<h3>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Experience</span></code></a></p></td>
<td><p>Definition of an experience. An experience contains a set of patterns</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.ScenarioStream" title="avalanche.benchmarks.ScenarioStream"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ScenarioStream</span></code></a></p></td>
<td><p>A scenario stream describes a sequence of incremental experiences.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a></p></td>
<td><p>Base implementation of a Continual Learning scenario. A Continual Learning</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.GenericScenarioStream" title="avalanche.benchmarks.GenericScenarioStream"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericScenarioStream</span></code></a></p></td>
<td><p>A scenario stream describes a sequence of incremental experiences.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.AbstractExperience" title="avalanche.benchmarks.AbstractExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">AbstractExperience</span></code></a></p></td>
<td><p>Definition of a learning experience. A learning experience contains a set of</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.GenericExperience" title="avalanche.benchmarks.GenericExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">GenericExperience</span></code></a></p></td>
<td><p>Definition of a learning experience based on a <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NCScenario</span></code></a></p></td>
<td><p>This class defines a “New Classes” scenario. Once created, an instance</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.NCExperience" title="avalanche.benchmarks.NCExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NCExperience</span></code></a></p></td>
<td><p>Defines a “New Classes” experience. It defines fields to obtain the current</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.NIScenario" title="avalanche.benchmarks.NIScenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NIScenario</span></code></a></p></td>
<td><p>This class defines a “New Instance” scenario.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.NIExperience" title="avalanche.benchmarks.NIExperience"><code class="xref py py-obj docutils literal notranslate"><span class="pre">NIExperience</span></code></a></p></td>
<td><p>Defines a “New Instances” experience. It defines fields to obtain the</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.Stream51" title="avalanche.benchmarks.Stream51"><code class="xref py py-obj docutils literal notranslate"><span class="pre">Stream51</span></code></a></p></td>
<td><p>Stream-51 Pytorch Dataset</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h3>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.create_multi_dataset_generic_scenario" title="avalanche.benchmarks.create_multi_dataset_generic_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_multi_dataset_generic_scenario</span></code></a>(train_dataset_list: Sequence[SupportedDataset], test_dataset_list: Sequence[SupportedDataset], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of datasets and the respective task</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.create_generic_scenario_from_filelists" title="avalanche.benchmarks.create_generic_scenario_from_filelists"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_filelists</span></code></a>(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of filelists and the respective task</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.create_generic_scenario_from_paths" title="avalanche.benchmarks.create_generic_scenario_from_paths"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_paths</span></code></a>(train_list_of_files: Sequence[Sequence[FileAndLabel]], test_list_of_files: Union[Sequence[FileAndLabel], Sequence[Sequence[FileAndLabel]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a sequence of lists of files. A separate</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.create_generic_scenario_from_tensors" title="avalanche.benchmarks.create_generic_scenario_from_tensors"><code class="xref py py-obj docutils literal notranslate"><span class="pre">create_generic_scenario_from_tensors</span></code></a>(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given lists of Tensors and the respective task</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.nc_scenario" title="avalanche.benchmarks.nc_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">nc_scenario</span></code></a>(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_experiences: int, task_labels: bool, *, shuffle: bool = True, seed: Optional[int] = None, fixed_class_order: Sequence[int] = None, per_exp_classes: Dict[int, int] = None, class_ids_from_zero_from_first_exp: bool = False, class_ids_from_zero_in_each_exp: bool = False, one_dataset_per_exp: bool = False, reproducibility_data: Dict[str, Any] = None) → NCScenario</p></td>
<td><p>This method is the high-level specific scenario generator for the</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.ni_scenario" title="avalanche.benchmarks.ni_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ni_scenario</span></code></a>(train_dataset: Union[Sequence[SupportedDataset], SupportedDataset], test_dataset: Union[Sequence[SupportedDataset], SupportedDataset], n_experiences: int, *, task_labels: bool = False, shuffle: bool = True, seed: Optional[int] = None, balance_experiences: bool = False, min_class_patterns_in_exp: int = 0, fixed_exp_assignment: Optional[Sequence[Sequence[int]]] = None, reproducibility_data: Optional[Dict[str, Any]] = None) → NIScenario</p></td>
<td><p>This method is the high-level specific scenario generator for the</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.dataset_scenario" title="avalanche.benchmarks.dataset_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">dataset_scenario</span></code></a>(train_dataset_list: Sequence[SupportedDataset], test_dataset_list: Sequence[SupportedDataset], task_labels: Sequence[int], *, complete_test_set_only: bool = False) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of datasets and the respective task</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.filelist_scenario" title="avalanche.benchmarks.filelist_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">filelist_scenario</span></code></a>(root: Union[str, Path], train_file_lists: Sequence[Union[str, Path]], test_file_lists: Union[Union[str, Path], Sequence[Union[str, Path]]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of filelists and the respective task</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.paths_scenario" title="avalanche.benchmarks.paths_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">paths_scenario</span></code></a>(train_list_of_files: Sequence[Sequence[FileAndLabel]], test_list_of_files: Union[Sequence[FileAndLabel], Sequence[Sequence[FileAndLabel]]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given a list of files and class labels.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.tensor_scenario" title="avalanche.benchmarks.tensor_scenario"><code class="xref py py-obj docutils literal notranslate"><span class="pre">tensor_scenario</span></code></a>(train_data_x: Sequence[Any], train_data_y: Sequence[Sequence[SupportsInt]], test_data_x: Union[Any, Sequence[Any]], test_data_y: Union[Any, Sequence[Sequence[SupportsInt]]], task_labels: Sequence[int], *, complete_test_set_only: bool = False, train_transform=None, train_target_transform=None, eval_transform=None, eval_target_transform=None) → GenericCLScenario</p></td>
<td><p>Creates a generic scenario given lists of Tensors and the respective task</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.CORe50" title="avalanche.benchmarks.CORe50"><code class="xref py py-obj docutils literal notranslate"><span class="pre">CORe50</span></code></a>(root=expanduser('~') + '/.avalanche/data/core50/', scenario='nicv2_391', run=0, train_transform=None, eval_transform=None)</p></td>
<td><p>Creates a CL scenario for CORe50.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitCIFAR10" title="avalanche.benchmarks.SplitCIFAR10"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitCIFAR10</span></code></a>(n_experiences: int, first_exp_with_half_classes: bool = False, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar10_train_transform, eval_transform=_default_cifar10_eval_transform) → NCScenario</p></td>
<td><p>Creates a CL scenario using the CIFAR10 dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitCIFAR100" title="avalanche.benchmarks.SplitCIFAR100"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitCIFAR100</span></code></a>(n_experiences: int, first_exp_with_half_classes: bool = False, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar100_train_transform, eval_transform=_default_cifar100_eval_transform)</p></td>
<td><p>Creates a CL scenario using the CIFAR100 dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitCIFAR110" title="avalanche.benchmarks.SplitCIFAR110"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitCIFAR110</span></code></a>(n_experiences: int, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar100_train_transform, eval_transform=_default_cifar100_eval_transform) → NCScenario</p></td>
<td><p>Creates a CL scenario using both the CIFAR100 and CIFAR10 datasets.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitCUB200" title="avalanche.benchmarks.SplitCUB200"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitCUB200</span></code></a>(root, n_experiences=11, classes_first_batch=100, return_task_id=False, seed=0, fixed_class_order=None, shuffle=False, train_transform=_default_train_transform, eval_transform=_default_eval_transform)</p></td>
<td><p>Creates a CL scenario using the Cub-200 dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitFMNIST" title="avalanche.benchmarks.SplitFMNIST"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitFMNIST</span></code></a>(n_experiences: int, first_batch_with_half_classes: bool = False, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_cifar10_train_transform, eval_transform=_default_cifar10_eval_transform)</p></td>
<td><p>Creates a CL scenario using the Fashion MNIST dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitImageNet" title="avalanche.benchmarks.SplitImageNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitImageNet</span></code></a>(root, n_experiences=10, per_exp_classes=None, return_task_id=False, seed=0, fixed_class_order=None, train_transform=_default_train_transform, eval_transform=_default_eval_transform)</p></td>
<td><p>Creates a CL scenario using the Tiny ImageNet dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitMNIST" title="avalanche.benchmarks.SplitMNIST"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitMNIST</span></code></a>(n_experiences: int, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_mnist_train_transform, eval_transform=_default_mnist_eval_transform)</p></td>
<td><p>Creates a CL scenario using the MNIST dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.PermutedMNIST" title="avalanche.benchmarks.PermutedMNIST"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PermutedMNIST</span></code></a>(n_experiences: int, seed: Optional[int] = None, train_transform: Any = _default_mnist_train_transform, eval_transform: Any = _default_mnist_eval_transform) → NCScenario</p></td>
<td><p>Creates a Permuted MNIST scenario.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.RotatedMNIST" title="avalanche.benchmarks.RotatedMNIST"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RotatedMNIST</span></code></a>(n_experiences: int, seed: Optional[int] = None, rotations_list: Optional[Sequence[int]] = None, train_transform=_default_mnist_train_transform, eval_transform=_default_mnist_eval_transform) → NCScenario</p></td>
<td><p>Creates a Rotated MNIST scenario.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitOmniglot" title="avalanche.benchmarks.SplitOmniglot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitOmniglot</span></code></a>(n_experiences: int, return_task_id=False, seed: Optional[int] = None, fixed_class_order: Optional[Sequence[int]] = None, train_transform=_default_omniglot_train_transform, eval_transform=_default_omniglot_eval_transform)</p></td>
<td><p>Creates a CL scenario using the OMNIGLOT dataset.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.PermutedOmniglot" title="avalanche.benchmarks.PermutedOmniglot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">PermutedOmniglot</span></code></a>(n_experiences: int, seed: Optional[int] = None, train_transform: Any = _default_omniglot_train_transform, eval_transform: Any = _default_omniglot_eval_transform) → NCScenario</p></td>
<td><p>Creates a Permuted Omniglot scenario.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.RotatedOmniglot" title="avalanche.benchmarks.RotatedOmniglot"><code class="xref py py-obj docutils literal notranslate"><span class="pre">RotatedOmniglot</span></code></a>(n_experiences: int, seed: Optional[int] = None, rotations_list: Optional[Sequence[int]] = None, train_transform=_default_omniglot_train_transform, eval_transform=_default_omniglot_eval_transform) → NCScenario</p></td>
<td><p>Creates a Rotated Omniglot scenario.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#avalanche.benchmarks.SplitTinyImageNet" title="avalanche.benchmarks.SplitTinyImageNet"><code class="xref py py-obj docutils literal notranslate"><span class="pre">SplitTinyImageNet</span></code></a>(n_experiences=10, return_task_id=False, seed=0, fixed_class_order=None, train_transform=_default_train_transform, eval_transform=_default_eval_transform)</p></td>
<td><p>Creates a CL scenario using the Tiny ImageNet dataset.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#avalanche.benchmarks.OpenLORIS" title="avalanche.benchmarks.OpenLORIS"><code class="xref py py-obj docutils literal notranslate"><span class="pre">OpenLORIS</span></code></a>(root=expanduser('~') + '/.avalanche/data/openloris/', factor='clutter', train_transform=None, eval_transform=None)</p></td>
<td><p>Creates a CL scenario for OpenLORIS.</p></td>
</tr>
</tbody>
</table>
<dl class="py data">
<dt id="avalanche.benchmarks.TrainSet">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">TrainSet</span></code><a class="headerlink" href="#avalanche.benchmarks.TrainSet" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py data">
<dt id="avalanche.benchmarks.TestSet">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">TestSet</span></code><a class="headerlink" href="#avalanche.benchmarks.TestSet" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.Experience">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">Experience</span></code><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#Experience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Experience" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Protocol[TScenario,</span> <span class="pre">TScenarioStream]</span></code></p>
<p>Definition of an experience. An experience contains a set of patterns
which has become available at a particular time instant. The content and
size of an Experience is defined by the specific benchmark that creates the
IExperience instance.</p>
<p>For instance, an experience of a New Classes scenario will contain all
patterns belonging to a subset of classes of the original training set. An
experience of a New Instance scenario will contain patterns from previously
seen classes.</p>
<p>Experiences of Single Incremental Task (a.k.a. task-free) scenarios are
usually called “batches” while in Multi Task scenarios an Experience is
usually associated to a “task”. Finally, in a Multi Incremental Task
scenario the Experience may be composed by patterns from different tasks.</p>
<dl class="py attribute">
<dt id="avalanche.benchmarks.Experience.origin_stream">
<code class="sig-name descname"><span class="pre">origin_stream</span></code><em class="property"> <span class="pre">:TScenarioStream</span></em><a class="headerlink" href="#avalanche.benchmarks.Experience.origin_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>A reference to the original stream from which this experience was obtained.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.Experience.scenario">
<code class="sig-name descname"><span class="pre">scenario</span></code><em class="property"> <span class="pre">:TScenario</span></em><a class="headerlink" href="#avalanche.benchmarks.Experience.scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>A reference to the scenario.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.Experience.current_experience">
<code class="sig-name descname"><span class="pre">current_experience</span></code><em class="property"> <span class="pre">:int</span></em><a class="headerlink" href="#avalanche.benchmarks.Experience.current_experience" title="Permalink to this definition">¶</a></dt>
<dd><p>This is an incremental, 0-indexed, value used to keep track of the position
of current experience in the original stream.</p>
<p>Beware that this value only describes the experience position in the
original stream and may be unrelated to the order in which the strategy will
encounter experiences.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Experience.dataset">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">AvalancheDataset</span><a class="headerlink" href="#avalanche.benchmarks.Experience.dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>The dataset containing the patterns available in this experience.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Experience.task_labels">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">task_labels</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#avalanche.benchmarks.Experience.task_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>This list will contain the unique task labels of the patterns contained
in this experience. In the most common scenarios this will be a list
with a single value. Note: for scenarios that don’t produce task labels,
a placeholder task label value like 0 is usually set to each pattern
(see the description of the originating scenario for details).</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Experience.task_label">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">task_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="headerlink" href="#avalanche.benchmarks.Experience.task_label" title="Permalink to this definition">¶</a></dt>
<dd><p>The task label. This value will never have value “None”. However,
for scenarios that don’t produce task labels a placeholder value like 0
is usually set. Beware that this field is meant as a shortcut to obtain
a unique task label: it assumes that only patterns labeled with a
single task label are present. If this experience contains patterns from
multiple tasks, accessing this property will result in an exception.</p>
</dd></dl>

</dd></dl>

<dl class="py data">
<dt id="avalanche.benchmarks.TExperience">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">TExperience</span></code><a class="headerlink" href="#avalanche.benchmarks.TExperience" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py data">
<dt id="avalanche.benchmarks.TScenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">TScenario</span></code><a class="headerlink" href="#avalanche.benchmarks.TScenario" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.ScenarioStream">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">ScenarioStream</span></code><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#ScenarioStream"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.ScenarioStream" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Protocol[TScenario,</span> <span class="pre">TExperience]</span></code></p>
<p>A scenario stream describes a sequence of incremental experiences.
Experiences are described as <code class="xref py py-class docutils literal notranslate"><span class="pre">IExperience</span></code> instances. They contain a
set of patterns which has become available at a particular time instant
along with any optional, scenario specific, metadata.</p>
<p>Most scenario expose two different streams: the training stream and the test
stream.</p>
<dl class="py attribute">
<dt id="avalanche.benchmarks.ScenarioStream.name">
<code class="sig-name descname"><span class="pre">name</span></code><em class="property"> <span class="pre">:str</span></em><a class="headerlink" href="#avalanche.benchmarks.ScenarioStream.name" title="Permalink to this definition">¶</a></dt>
<dd><p>The name of the stream.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.ScenarioStream.scenario">
<code class="sig-name descname"><span class="pre">scenario</span></code><em class="property"> <span class="pre">:TScenario</span></em><a class="headerlink" href="#avalanche.benchmarks.ScenarioStream.scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>A reference to the scenario this stream belongs to.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.ScenarioStream.__getitem__">
<code class="sig-name descname"><span class="pre">__getitem__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.TScenarioStream" title="avalanche.benchmarks.TScenarioStream"><span class="pre">TScenarioStream</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">experience_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">slice</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.TExperience" title="avalanche.benchmarks.TExperience"><span class="pre">TExperience</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.TScenarioStream" title="avalanche.benchmarks.TScenarioStream"><span class="pre">TScenarioStream</span></a><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#ScenarioStream.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.ScenarioStream.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets an experience given its experience index (or a stream slice given
the experience order).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>experience_idx</strong> – An int describing the experience index or an
iterable/slice object describing a slice of this stream.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The Experience instance associated to the given experience
index or a sliced stream instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.ScenarioStream.__len__">
<code class="sig-name descname"><span class="pre">__len__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_definitions/#ScenarioStream.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.ScenarioStream.__len__" title="Permalink to this definition">¶</a></dt>
<dd><p>Used to get the length of this stream (the amount of experiences).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The amount of experiences in this stream.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py data">
<dt id="avalanche.benchmarks.TScenarioStream">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">TScenarioStream</span></code><a class="headerlink" href="#avalanche.benchmarks.TScenarioStream" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py data">
<dt id="avalanche.benchmarks.TGenericCLScenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">TGenericCLScenario</span></code><a class="headerlink" href="#avalanche.benchmarks.TGenericCLScenario" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.GenericCLScenario">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">GenericCLScenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TGenericCLScenario,</span> <span class="pre">original_train_dataset:</span> <span class="pre">TrainSet,</span> <span class="pre">original_test_dataset:</span> <span class="pre">TestSet,</span> <span class="pre">train_dataset:</span> <span class="pre">AvalancheDataset,</span> <span class="pre">test_dataset:</span> <span class="pre">AvalancheDataset,</span> <span class="pre">train_exps_patterns_assignment:</span> <span class="pre">Sequence[Sequence[int]],</span> <span class="pre">test_exps_patterns_assignment:</span> <span class="pre">Sequence[Sequence[int]],</span> <span class="pre">task_labels:</span> <span class="pre">Sequence[List[int]],</span> <span class="pre">pattern_train_task_labels:</span> <span class="pre">Sequence[int],</span> <span class="pre">pattern_test_task_labels:</span> <span class="pre">Sequence[int],</span> <span class="pre">complete_test_set_only:</span> <span class="pre">bool</span> <span class="pre">=</span> <span class="pre">False,</span> <span class="pre">reproducibility_data:</span> <span class="pre">Optional[Dict[str,</span> <span class="pre">Any]]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">experience_factory:</span> <span class="pre">Callable[['GenericScenarioStream',</span> <span class="pre">int],</span> <span class="pre">TExperience]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericCLScenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TrainSet,</span> <span class="pre">TestSet,</span> <span class="pre">TExperience]</span></code></p>
<p>Base implementation of a Continual Learning scenario. A Continual Learning
scenario is defined by a sequence of experiences (batches or tasks depending
on the terminology), with each experience containing the training (or test)
data that becomes available at a certain time instant.</p>
<p>From a practical point of view, this means that we usually have to define
two datasets (training and test), and some way to assign the patterns
contained in these datasets to each experience.</p>
<p>This assignment is usually made in children classes, with this class serving
as the more general implementation. This class handles the most simple type
of assignment: each experience is defined by a list of patterns (identified
by their indexes) contained in that experience.</p>
<p>Creates an instance of a Continual Learning scenario.</p>
<p>The scenario is defined by the train and test datasets plus the
assignment of patterns to experiences (batches/tasks).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – The training dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">train_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>test_dataset</strong> – The test dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">test_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>train_exps_patterns_assignment</strong> – A list of experiences. Each
experience is in turn defined by a list of integers describing the
pattern index inside the training dataset.</p></li>
<li><p><strong>test_exps_patterns_assignment</strong> – A list of experiences. Each
experience is in turn defined by a list of integers describing the
pattern index inside the test dataset.</p></li>
<li><p><strong>task_labels</strong> – The mapping from experience IDs to task labels,
usually as a list of integers.</p></li>
<li><p><strong>pattern_train_task_labels</strong> – The list of task labels of each
pattern in the <cite>train_dataset</cite>.</p></li>
<li><p><strong>pattern_test_task_labels</strong> – The list of task labels of each
pattern in the <cite>test_dataset</cite>.</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test
set will be returned from test set related methods of the linked
<a class="reference internal" href="#avalanche.benchmarks.GenericExperience" title="avalanche.benchmarks.GenericExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience</span></code></a> instances. This also means that the
<code class="docutils literal notranslate"><span class="pre">test_exps_patterns_assignment</span></code> parameter can be a single element
or even an empty list (in which case, the full set defined by
the <code class="docutils literal notranslate"><span class="pre">test_dataset</span></code> parameter will be returned). The returned
task label for the complete test set will be the first element
of the <code class="docutils literal notranslate"><span class="pre">task_labels</span></code> parameter. Defaults to False, which means
that <code class="docutils literal notranslate"><span class="pre">`train_exps_patterns_assignment</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_exps_patterns_assignment</span></code> parameters must describe an equal
amount of experiences.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides the
<code class="docutils literal notranslate"><span class="pre">train/test_exps_patterns_assignment</span></code> and <code class="docutils literal notranslate"><span class="pre">task_labels</span></code>
parameters. This is usually a dictionary containing data used to
reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
<li><p><strong>experience_factory</strong> – If not None, a callable that, given the
scenario instance and the experience ID, returns a experience
instance. This parameter is usually used in subclasses (when
invoking the super constructor) to specialize the experience class.
Defaults to None, which means that the <a class="reference internal" href="#avalanche.benchmarks.GenericExperience" title="avalanche.benchmarks.GenericExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience</span></code></a>
constructor will be used.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.original_train_dataset">
<code class="sig-name descname"><span class="pre">original_train_dataset</span></code><em class="property"> <span class="pre">:TrainSet</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.original_train_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>The original training set.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.original_test_dataset">
<code class="sig-name descname"><span class="pre">original_test_dataset</span></code><em class="property"> <span class="pre">:TestSet</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.original_test_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>The original test set.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.train_exps_patterns_assignment">
<code class="sig-name descname"><span class="pre">train_exps_patterns_assignment</span></code><em class="property"> <span class="pre">:Sequence[Sequence[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.train_exps_patterns_assignment" title="Permalink to this definition">¶</a></dt>
<dd><p>A list containing which training patterns are assigned to each
experience. Patterns are identified by their id w.r.t. the dataset found
in the train_dataset field.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.test_exps_patterns_assignment">
<code class="sig-name descname"><span class="pre">test_exps_patterns_assignment</span></code><em class="property"> <span class="pre">:Sequence[Sequence[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.test_exps_patterns_assignment" title="Permalink to this definition">¶</a></dt>
<dd><p>A list containing which test patterns are assigned to each
experience. Patterns are identified by their id w.r.t. the dataset found
in the test_dataset field</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.task_labels">
<code class="sig-name descname"><span class="pre">task_labels</span></code><em class="property"> <span class="pre">:Sequence[List[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.task_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>The task label of each experience.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.pattern_train_task_labels">
<code class="sig-name descname"><span class="pre">pattern_train_task_labels</span></code><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.pattern_train_task_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>The task label of each pattern in the training dataset.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.pattern_test_task_labels">
<code class="sig-name descname"><span class="pre">pattern_test_task_labels</span></code><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.pattern_test_task_labels" title="Permalink to this definition">¶</a></dt>
<dd><p>The task label of each pattern in the test dataset.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.complete_test_set_only">
<code class="sig-name descname"><span class="pre">complete_test_set_only</span></code><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.complete_test_set_only" title="Permalink to this definition">¶</a></dt>
<dd><p>If True, only the complete test set will be returned from experience
instances.</p>
<p>This flag is usually set to True in scenarios where having one separate
test set aligned to each training experience is impossible or doesn’t
make sense from a semantic point of view.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.n_experiences">
<code class="sig-name descname"><span class="pre">n_experiences</span></code><em class="property"> <span class="pre">:int</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.n_experiences" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of incremental experiences this scenario is made of.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.train_dataset">
<code class="sig-name descname"><span class="pre">train_dataset</span></code><em class="property"> <span class="pre">:AvalancheDataset</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.train_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>The training set used to generate the incremental experiences.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.test_dataset">
<code class="sig-name descname"><span class="pre">test_dataset</span></code><em class="property"> <span class="pre">:AvalancheDataset</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.test_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>The test set used to generate the incremental experiences.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.train_stream">
<code class="sig-name descname"><span class="pre">train_stream</span></code><em class="property"> <span class="pre">:GenericScenarioStream[TExperience,</span> <span class="pre">TGenericCLScenario]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.train_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>The stream used to obtain the training experiences.
This stream can be sliced in order to obtain a subset of this stream.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericCLScenario.test_stream">
<code class="sig-name descname"><span class="pre">test_stream</span></code><em class="property"> <span class="pre">:GenericScenarioStream[TExperience,</span> <span class="pre">TGenericCLScenario]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.test_stream" title="Permalink to this definition">¶</a></dt>
<dd><p>The stream used to obtain the test experiences. This stream can be
sliced in order to obtain a subset of this stream.</p>
<p>Beware that, in certain scenarios, this stream may contain a single
element. Check the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> field for more details.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericCLScenario.get_reproducibility_data">
<code class="sig-name descname"><span class="pre">get_reproducibility_data</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericCLScenario.get_reproducibility_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.get_reproducibility_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the data needed to reproduce this experiment.</p>
<p>This data can be stored using the pickle module or some other mechanism.
It can then be loaded by passing it as the <code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code>
parameter in the constructor.</p>
<p>Child classes should get the reproducibility dictionary from super class
and then merge their custom data before returning it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing the data needed to reproduce the
experiment.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericCLScenario.get_classes_timeline">
<code class="sig-name descname"><span class="pre">get_classes_timeline</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericCLScenario.get_classes_timeline"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.get_classes_timeline" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the classes timeline for a this scenario.</p>
<p>Given a experience ID, this method returns the classes in this
experience, previously seen classes, the cumulative class list and a
list of classes that will be encountered in next experiences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>current_experience</strong> – The reference experience ID.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A tuple composed of four lists: the first list contains the
IDs of classes in this experience, the second contains IDs of
classes seen in previous experiences, the third returns a cumulative
list of classes (that is, the union of the first two list) while the
last one returns a list of classes that will be encountered in next
experiences.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericCLScenario.classes_in_experience">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">classes_in_experience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#avalanche.benchmarks.GenericCLScenario.classes_in_experience" title="Permalink to this definition">¶</a></dt>
<dd><p>A list that, for each experience (identified by its index/ID),
stores a set of the (optionally remapped) IDs of classes of patterns
assigned to that experience.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.GenericScenarioStream">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">GenericScenarioStream</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TGenericScenarioStream</span></em>, <em class="sig-param"><span class="pre">name:</span> <span class="pre">str</span></em>, <em class="sig-param"><span class="pre">scenario:</span> <span class="pre">TGenericCLScenario</span></em>, <em class="sig-param"><span class="pre">*</span></em>, <em class="sig-param"><span class="pre">slice_ids:</span> <span class="pre">List[int]</span> <span class="pre">=</span> <span class="pre">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericScenarioStream" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TExperience,</span> <span class="pre">TGenericCLScenario]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">ScenarioStream[TGenericCLScenario,</span> <span class="pre">TExperience]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Sequence[TExperience]</span></code></p>
<p>A scenario stream describes a sequence of incremental experiences.
Experiences are described as <code class="xref py py-class docutils literal notranslate"><span class="pre">IExperience</span></code> instances. They contain a
set of patterns which has become available at a particular time instant
along with any optional, scenario specific, metadata.</p>
<p>Most scenario expose two different streams: the training stream and the test
stream.</p>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py attribute">
<dt id="avalanche.benchmarks.GenericScenarioStream.slice_ids">
<code class="sig-name descname"><span class="pre">slice_ids</span></code><em class="property"> <span class="pre">:Optional[List[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.GenericScenarioStream.slice_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Describes which experiences are contained in the current stream slice.
Can be None, which means that this object is the original stream.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericScenarioStream.__len__">
<code class="sig-name descname"><span class="pre">__len__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericScenarioStream.__len__" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the number of experiences this scenario it’s made of.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The number of experiences in this scenario.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericScenarioStream.__getitem__">
<code class="sig-name descname"><span class="pre">__getitem__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_idx</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">slice</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Union</span><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.TExperience" title="avalanche.benchmarks.TExperience"><span class="pre">TExperience</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.TScenarioStream" title="avalanche.benchmarks.TScenarioStream"><span class="pre">TScenarioStream</span></a><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericScenarioStream.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a experience given its experience index (or a stream slice given
the experience order).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>exp_idx</strong> – An int describing the experience index or an
iterable/slice object describing a slice of this stream.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The experience instance associated to the given experience
index or a sliced stream instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericScenarioStream._create_slice">
<code class="sig-name descname"><span class="pre">_create_slice</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">TGenericScenarioStream</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exps_slice</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">slice</span><span class="p"><span class="pre">,</span> </span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.TScenarioStream" title="avalanche.benchmarks.TScenarioStream"><span class="pre">TScenarioStream</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericScenarioStream._create_slice"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericScenarioStream._create_slice" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a sliced version of this stream.</p>
<p>In its base version, a shallow copy of this stream is created and
then its <code class="docutils literal notranslate"><span class="pre">slice_ids</span></code> field is adapted.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>exps_slice</strong> – The slice to use.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A sliced version of this stream.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.AbstractExperience">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">AbstractExperience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TExperience,</span> <span class="pre">origin_stream:</span> <span class="pre">TScenarioStream,</span> <span class="pre">current_experience:</span> <span class="pre">int,</span> <span class="pre">classes_in_this_exp:</span> <span class="pre">Sequence[int],</span> <span class="pre">previous_classes:</span> <span class="pre">Sequence[int],</span> <span class="pre">classes_seen_so_far:</span> <span class="pre">Sequence[int],</span> <span class="pre">future_classes:</span> <span class="pre">Optional[Sequence[int]]</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#AbstractExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.AbstractExperience" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Experience[TScenario,</span> <span class="pre">TScenarioStream]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Definition of a learning experience. A learning experience contains a set of
patterns which has become available at a particular time instant. The
content and size of an Experience is defined by the specific benchmark that
creates the experience.</p>
<p>For instance, an experience of a New Classes scenario will contain all
patterns belonging to a subset of classes of the original training set. An
experience of a New Instance scenario will contain patterns from previously
seen classes.</p>
<p>Experiences of Single Incremental Task (a.k.a. task-free) scenarios are
usually called “batches” while in Multi Task scenarios an Experience is
usually associated to a “task”. Finally, in a Multi Incremental Task
scenario the Experience may be composed by patterns from different tasks.</p>
<p>Creates an instance of the abstract experience given the scenario
stream, the current experience ID and data about the classes timeline.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
<li><p><strong>classes_in_this_exp</strong> – The list of classes in this experience.</p></li>
<li><p><strong>previous_classes</strong> – The list of classes in previous experiences.</p></li>
<li><p><strong>classes_seen_so_far</strong> – List of classes of current and previous
experiences.</p></li>
<li><p><strong>future_classes</strong> – The list of classes of next experiences.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.benchmarks.AbstractExperience.classes_in_this_experience">
<code class="sig-name descname"><span class="pre">classes_in_this_experience</span></code><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.AbstractExperience.classes_in_this_experience" title="Permalink to this definition">¶</a></dt>
<dd><p>The list of classes in this experience</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.AbstractExperience.previous_classes">
<code class="sig-name descname"><span class="pre">previous_classes</span></code><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.AbstractExperience.previous_classes" title="Permalink to this definition">¶</a></dt>
<dd><p>The list of classes in previous experiences</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.AbstractExperience.classes_seen_so_far">
<code class="sig-name descname"><span class="pre">classes_seen_so_far</span></code><em class="property"> <span class="pre">:Sequence[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.AbstractExperience.classes_seen_so_far" title="Permalink to this definition">¶</a></dt>
<dd><p>List of classes of current and previous experiences</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.AbstractExperience.future_classes">
<code class="sig-name descname"><span class="pre">future_classes</span></code><em class="property"> <span class="pre">:Optional[Sequence[int]]</span></em><a class="headerlink" href="#avalanche.benchmarks.AbstractExperience.future_classes" title="Permalink to this definition">¶</a></dt>
<dd><p>The list of classes of next experiences</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.AbstractExperience.task_label">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">task_label</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">int</span><a class="headerlink" href="#avalanche.benchmarks.AbstractExperience.task_label" title="Permalink to this definition">¶</a></dt>
<dd><p>The task label. This value will never have value “None”. However,
for scenarios that don’t produce task labels a placeholder value like 0
is usually set. Beware that this field is meant as a shortcut to obtain
a unique task label: it assumes that only patterns labeled with a
single task label are present. If this experience contains patterns from
multiple tasks, accessing this property will result in an exception.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.GenericExperience">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">GenericExperience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="pre">:</span> <span class="pre">TGenericExperience,</span> <span class="pre">origin_stream:</span> <span class="pre">GenericScenarioStream[TGenericExperience,</span> <span class="pre">TGenericCLScenario],</span> <span class="pre">current_experience:</span> <span class="pre">int</span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericExperience" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">AbstractExperience[TGenericCLScenario,</span> <span class="pre">GenericScenarioStream[TGenericExperience,</span> <span class="pre">TGenericCLScenario]]</span></code></p>
<p>Definition of a learning experience based on a <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a>
instance.</p>
<p>This experience implementation uses the generic experience-patterns
assignment defined in the <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance. Instances of
this class are usually obtained from a scenario stream.</p>
<p>Creates an instance of a generic experience given the stream from this
experience was taken and and the current experience ID.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.benchmarks.GenericExperience.dataset">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">dataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">AvalancheDataset</span><a class="headerlink" href="#avalanche.benchmarks.GenericExperience.dataset" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericExperience.task_labels">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">task_labels</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#avalanche.benchmarks.GenericExperience.task_labels" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.GenericExperience._is_train">
<code class="sig-name descname"><span class="pre">_is_train</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_cl_scenario/#GenericExperience._is_train"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.GenericExperience._is_train" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.create_multi_dataset_generic_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">create_multi_dataset_generic_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_multi_dataset_generic_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.create_multi_dataset_generic_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of datasets and the respective task
labels. Each training dataset will be considered as a separate training
experience. Contents of the datasets will not be changed, including the
targets.</p>
<p>When loading the datasets from a set of fixed filelist, consider using
the <a class="reference internal" href="#avalanche.benchmarks.create_generic_scenario_from_filelists" title="avalanche.benchmarks.create_generic_scenario_from_filelists"><code class="xref py py-func docutils literal notranslate"><span class="pre">create_generic_scenario_from_filelists()</span></code></a> helper method instead.</p>
<p>In its base form, this function accepts a list of test datsets that must
contain the same amount of datasets of the training list.
Those pairs are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>Beware that pattern transformations must already be included in the
datasets (when needed).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset_list</strong> – A list of training datasets.</p></li>
<li><p><strong>test_dataset_list</strong> – A list of test datasets.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code>
parameter must be list with a single element (the complete test set).
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code> must contain the same amount of datasets.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.create_generic_scenario_from_filelists">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">create_generic_scenario_from_filelists</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_file_lists</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_file_lists</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_filelists"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.create_generic_scenario_from_filelists" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of filelists and the respective task
labels. A separate dataset will be created for each filelist and each of
those training datasets will be considered a separate training experience.
Contents of the datasets will not be changed, including the targets.</p>
<p>In its base form, this function accepts a list of filelists for the test
datsets that must contain the same amount of elements of the training list.
Those pairs of datasets are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>This helper functions is the best shot when loading Caffe-style dataset
based on filelists.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – The root path of the dataset.</p></li>
<li><p><strong>train_file_lists</strong> – A list of filelists describing the
paths of the training patterns for each experience.</p></li>
<li><p><strong>test_file_lists</strong> – A list of filelists describing the
paths of the test patterns for each experience.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code>
parameter must be list with a single element (the complete test set).
Alternatively, can be a plain string or <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code> object.
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.create_generic_scenario_from_paths">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">create_generic_scenario_from_paths</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_list_of_files</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_list_of_files</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_paths"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.create_generic_scenario_from_paths" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a sequence of lists of files. A separate
dataset will be created for each list. Each of those training datasets
will be considered a separate training experience.</p>
<p>This is very similar to <cite>create_generic_scenario_from_filelists</cite>, with the
main difference being that <cite>create_generic_scenario_from_filelists</cite>
accepts, for each experience, a file list formatted in Caffe-style.
On the contrary, this accepts a list of tuples where each tuple contains
two elements: the full path to the pattern and its label.
Optionally, the tuple may contain a third element describing the bounding
box of the element to crop. This last bounding box may be useful when trying
to extract the part of the image depicting the desired element.</p>
<p>In its base form, this function accepts a list for the test datsets that
must contain the same amount of elements of the training list.
Those pairs of datasets are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_list_of_files</strong> – A list of lists. Each list describes the paths
and labels of patterns to include in that training experience, as
tuples. Each tuple must contain two elements: the full path to the
pattern and its class label. Optionally, the tuple may contain a
third element describing the bounding box to use for cropping (top,
left, height, width).</p></li>
<li><p><strong>test_list_of_files</strong> – A list of lists. Each list describes the paths
and labels of patterns to include in that test experience, as tuples.
Each tuple must contain two elements: the full path to the pattern
and its class label. Optionally, the tuple may contain a third element
describing the bounding box to use for cropping (top, left, height,
width).</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code>
parameter must be list with a single element (the complete test set).
Alternatively, can be a plain string or <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code> object.
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.create_generic_scenario_from_tensors">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">create_generic_scenario_from_tensors</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data_x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportsInt</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_data_x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_data_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportsInt</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/generic_scenario_creation/#create_generic_scenario_from_tensors"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.create_generic_scenario_from_tensors" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given lists of Tensors and the respective task
labels. A separate dataset will be created from each Tensor pair (x + y)
and each of those training datasets will be considered a separate
training experience. Contents of the datasets will not be changed, including
the targets. Using this helper function is the lower level way to create a
Continual Learning scenario. When possible, consider using higher level
helpers.</p>
<p>In its base form, the test lists must contain the same amount of elements of
the training lists. Those pairs of datasets are then used to create the
“past”, “cumulative” (a.k.a. growing) and “future” test sets.
However, in certain Continual Learning scenarios only the concept of
“complete” test set makes sense. In that case, the
<code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the parameter
description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data_x</strong> – A list of Tensors (one per experience) containing the
patterns of the training sets.</p></li>
<li><p><strong>train_data_y</strong> – A list of Tensors or int lists containing the
labels of the patterns of the training sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code>.</p></li>
<li><p><strong>test_data_x</strong> – A Tensor or a list of Tensors (one per experience)
containing the patterns of the test sets.</p></li>
<li><p><strong>test_data_y</strong> – A Tensor or a list of Tensors or int lists containing
the labels of the patterns of the test sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code>.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_datasets_y</span></code> parameters must be lists with a single element
(the complete test set). Defaults to False, which means that
<code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same
amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.NCScenario">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">NCScenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.TrainSet" title="avalanche.benchmarks.TrainSet"><span class="pre">TrainSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.TestSet" title="avalanche.benchmarks.TestSet"><span class="pre">TestSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_experience_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_ids_from_zero_from_first_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_ids_from_zero_in_each_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reproducibility_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCScenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NCScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario[TrainSet,</span> <span class="pre">TestSet,</span> <span class="pre">'NCExperience']</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TrainSet,</span> <span class="pre">TestSet]</span></code></p>
<p>This class defines a “New Classes” scenario. Once created, an instance
of this class can be iterated in order to obtain the experience sequence
under the form of instances of <a class="reference internal" href="#avalanche.benchmarks.NCExperience" title="avalanche.benchmarks.NCExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCExperience</span></code></a>.</p>
<p>This class can be used directly. However, we recommend using facilities like
<a class="reference internal" href="generators/#avalanche.benchmarks.generators.nc_scenario" title="avalanche.benchmarks.generators.nc_scenario"><code class="xref py py-func docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators.nc_scenario()</span></code></a>.</p>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">NCGenericScenario</span></code> instance given the training and test
Datasets and the number of experiences.</p>
<p>By default, the number of classes will be automatically detected by
looking at the training Dataset <code class="docutils literal notranslate"><span class="pre">targets</span></code> field. Classes will be
uniformly distributed across <code class="docutils literal notranslate"><span class="pre">n_experiences</span></code> unless a
<code class="docutils literal notranslate"><span class="pre">per_experience_classes</span></code> argument is specified.</p>
<p>The number of classes must be divisible without remainder by the number
of experiences. This also applies when the <code class="docutils literal notranslate"><span class="pre">per_experience_classes</span></code>
argument is not None.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – The training dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">train_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>test_dataset</strong> – The test dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">test_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences.</p></li>
<li><p><strong>task_labels</strong> – If True, each experience will have an ascending task
label. If False, the task label will be 0 for all the experiences.</p></li>
<li><p><strong>shuffle</strong> – If True, the class order will be shuffled. Defaults to
True.</p></li>
<li><p><strong>seed</strong> – If shuffle is True and seed is not None, the class order
will be shuffled according to the seed. When None, the current
PyTorch random number generator state will be used.
Defaults to None.</p></li>
<li><p><strong>fixed_class_order</strong> – If not None, the class order to use (overrides
the shuffle argument). Very useful for enhancing
reproducibility. Defaults to None.</p></li>
<li><p><strong>per_experience_classes</strong> – Is not None, a dictionary whose keys are
(0-indexed) experience IDs and their values are the number of
classes to include in the respective experiences. The dictionary
doesn’t have to contain a key for each experience! All the remaining
experiences will contain an equal amount of the remaining classes.
The remaining number of classes must be divisible without remainder
by the remaining number of experiences. For instance,
if you want to include 50 classes in the first experience
while equally distributing remaining classes across remaining
experiences, just pass the “{0: 50}” dictionary as the
per_experience_classes parameter. Defaults to None.</p></li>
<li><p><strong>class_ids_from_zero_from_first_exp</strong> – If True, original class IDs
will be remapped so that they will appear as having an ascending
order. For instance, if the resulting class order after shuffling
(or defined by fixed_class_order) is [23, 34, 11, 7, 6, …] and
class_ids_from_zero_from_first_exp is True, then all the patterns
belonging to class 23 will appear as belonging to class “0”,
class “34” will be mapped to “1”, class “11” to “2” and so on.
This is very useful when drawing confusion matrices and when dealing
with algorithms with dynamic head expansion. Defaults to False.
Mutually exclusive with the <code class="docutils literal notranslate"><span class="pre">class_ids_from_zero_in_each_exp</span></code>
parameter.</p></li>
<li><p><strong>class_ids_from_zero_in_each_exp</strong> – If True, original class IDs
will be mapped to range [0, n_classes_in_exp) for each experience.
Defaults to False. Mutually exclusive with the
<code class="docutils literal notranslate"><span class="pre">class_ids_from_zero_from_first_exp</span> <span class="pre">parameter</span></code>.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options. This is usually a dictionary containing
data used to reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.classes_order">
<code class="sig-name descname"><span class="pre">classes_order</span></code><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.classes_order" title="Permalink to this definition">¶</a></dt>
<dd><p>Stores the class order (remapped class IDs).</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.classes_order_original_ids">
<code class="sig-name descname"><span class="pre">classes_order_original_ids</span></code><em class="property"> <span class="pre">:List[int]</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.classes_order_original_ids" title="Permalink to this definition">¶</a></dt>
<dd><p>Stores the class order (original class IDs)</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.class_mapping">
<code class="sig-name descname"><span class="pre">class_mapping</span></code><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.class_mapping" title="Permalink to this definition">¶</a></dt>
<dd><p>class_mapping stores the class mapping so that
<cite>mapped_class_id = class_mapping[original_class_id]</cite>.</p>
<p>If the scenario is created with an amount of classes which is less than
the amount of all classes in the dataset, then class_mapping will
contain some -1 values corresponding to ignored classes. This can
happen when passing a fixed class order to the constructor.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.n_classes_per_exp">
<code class="sig-name descname"><span class="pre">n_classes_per_exp</span></code><em class="property"> <span class="pre">:List[int]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.n_classes_per_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>A list that, for each experience (identified by its index/ID),
stores the number of classes assigned to that experience.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.original_classes_in_exp">
<code class="sig-name descname"><span class="pre">original_classes_in_exp</span></code><em class="property"> <span class="pre">:List[Set[int]]</span> <span class="pre">=</span> <span class="pre">[]</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.original_classes_in_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>A list that, for each experience (identified by its index/ID),
stores a list of the original IDs of classes assigned
to that experience.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.class_ids_from_zero_from_first_exp">
<code class="sig-name descname"><span class="pre">class_ids_from_zero_from_first_exp</span></code><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.class_ids_from_zero_from_first_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>If True the class IDs have been remapped to start from zero.</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.class_ids_from_zero_in_each_exp">
<code class="sig-name descname"><span class="pre">class_ids_from_zero_in_each_exp</span></code><em class="property"> <span class="pre">:bool</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.class_ids_from_zero_in_each_exp" title="Permalink to this definition">¶</a></dt>
<dd><p>If True the class IDs have been remapped to start from zero in
each experience</p>
</dd></dl>

<dl class="py attribute">
<dt id="avalanche.benchmarks.NCScenario.n_classes">
<code class="sig-name descname"><span class="pre">n_classes</span></code><em class="property"> <span class="pre">:int</span></em><a class="headerlink" href="#avalanche.benchmarks.NCScenario.n_classes" title="Permalink to this definition">¶</a></dt>
<dd><p>The number of classes</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.NCScenario.classes_in_experience">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">classes_in_experience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#avalanche.benchmarks.NCScenario.classes_in_experience" title="Permalink to this definition">¶</a></dt>
<dd><p>A list that, for each experience (identified by its index/ID),
stores a set of the (optionally remapped) IDs of classes of patterns
assigned to that experience.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.NCScenario.get_reproducibility_data">
<code class="sig-name descname"><span class="pre">get_reproducibility_data</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCScenario.get_reproducibility_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NCScenario.get_reproducibility_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the data needed to reproduce this experiment.</p>
<p>This data can be stored using the pickle module or some other mechanism.
It can then be loaded by passing it as the <code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code>
parameter in the constructor.</p>
<p>Child classes should get the reproducibility dictionary from super class
and then merge their custom data before returning it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing the data needed to reproduce the
experiment.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.NCScenario.classes_in_exp_range">
<code class="sig-name descname"><span class="pre">classes_in_exp_range</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_start</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_end</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">List</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCScenario.classes_in_exp_range"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NCScenario.classes_in_exp_range" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets a list of classes contained in the given experiences. The
experiences are defined by range. This means that only the classes in
range [exp_start, exp_end) will be included.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>exp_start</strong> – The starting experience ID.</p></li>
<li><p><strong>exp_end</strong> – The final experience ID. Can be None, which means that
all the remaining experiences will be taken.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The classes contained in the required experience range.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.NCExperience">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">NCExperience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">origin_stream</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.GenericScenarioStream" title="avalanche.benchmarks.GenericScenarioStream"><span class="pre">GenericScenarioStream</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.NCExperience" title="avalanche.benchmarks.NCExperience"><span class="pre">NCExperience</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.TrainSet" title="avalanche.benchmarks.TrainSet"><span class="pre">TrainSet</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.TestSet" title="avalanche.benchmarks.TestSet"><span class="pre">TestSet</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_classes/nc_scenario/#NCExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NCExperience" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience[NCScenario[TrainSet,</span> <span class="pre">TestSet],</span> <span class="pre">GenericScenarioStream['NCExperience',</span> <span class="pre">NCScenario[TrainSet,</span> <span class="pre">TestSet]]]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TrainSet,</span> <span class="pre">TestSet]</span></code></p>
<p>Defines a “New Classes” experience. It defines fields to obtain the current
dataset and the associated task label. It also keeps a reference to the
stream from which this experience was taken.</p>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">NCExperience</span></code> instance given the stream from this
experience was taken and and the current experience ID.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.NIScenario">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">NIScenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.TrainSet" title="avalanche.benchmarks.TrainSet"><span class="pre">TrainSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.TestSet" title="avalanche.benchmarks.TestSet"><span class="pre">TestSet</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_class_patterns_in_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_exp_assignment</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reproducibility_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_instances/ni_scenario/#NIScenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NIScenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario[TrainSet,</span> <span class="pre">TestSet,</span> <span class="pre">'NIExperience']</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TrainSet,</span> <span class="pre">TestSet]</span></code></p>
<p>This class defines a “New Instance” scenario.
Once created, an instance of this class can be iterated in order to obtain
the experience sequence under the form of instances of
<a class="reference internal" href="#avalanche.benchmarks.NIExperience" title="avalanche.benchmarks.NIExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">NIExperience</span></code></a>.</p>
<p>Instances of this class can be created using the constructor directly.
However, we recommend using facilities like
<a class="reference internal" href="generators/#avalanche.benchmarks.generators.ni_scenario" title="avalanche.benchmarks.generators.ni_scenario"><code class="xref py py-func docutils literal notranslate"><span class="pre">avalanche.benchmarks.generators.ni_scenario()</span></code></a>.</p>
<p>Consider that every method from <a class="reference internal" href="#avalanche.benchmarks.NIExperience" title="avalanche.benchmarks.NIExperience"><code class="xref py py-class docutils literal notranslate"><span class="pre">NIExperience</span></code></a> used to retrieve
parts of the test set (past, current, future, cumulative) always return the
complete test set. That is, they behave as the getter for the complete test
set.</p>
<p>Creates a NIScenario instance given the training and test Datasets and
the number of experiences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – The training dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">train_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>test_dataset</strong> – The test dataset. The dataset must be a
subclass of <code class="xref py py-class docutils literal notranslate"><span class="pre">AvalancheDataset</span></code>. For instance, one can
use the datasets from the torchvision package like that:
<code class="docutils literal notranslate"><span class="pre">test_dataset=AvalancheDataset(torchvision_dataset)</span></code>.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences.</p></li>
<li><p><strong>task_labels</strong> – If True, each experience will have an ascending task
label. If False, the task label will be 0 for all the experiences.
Defaults to False.</p></li>
<li><p><strong>shuffle</strong> – If True, the patterns order will be shuffled. Defaults
to True.</p></li>
<li><p><strong>seed</strong> – If shuffle is True and seed is not None, the class order
will be shuffled according to the seed. When None, the current
PyTorch random number generator state will be used.
Defaults to None.</p></li>
<li><p><strong>balance_experiences</strong> – If True, pattern of each class will be
equally spread across all experiences. If False, patterns will be
assigned to experiences in a complete random way. Defaults to False.</p></li>
<li><p><strong>min_class_patterns_in_exp</strong> – The minimum amount of patterns of
every class that must be assigned to every experience. Compatible
with the <code class="docutils literal notranslate"><span class="pre">balance_experiences</span></code> parameter. An exception will be
raised if this constraint can’t be satisfied. Defaults to 0.</p></li>
<li><p><strong>fixed_exp_assignment</strong> – If not None, the pattern assignment
to use. It must be a list with an entry for each experience. Each
entry is a list that contains the indexes of patterns belonging to
that experience. Overrides the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="docutils literal notranslate"><span class="pre">balance_experiences</span></code>
and <code class="docutils literal notranslate"><span class="pre">min_class_patterns_in_exp</span></code> parameters.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options, including <code class="docutils literal notranslate"><span class="pre">fixed_exp_assignment</span></code>.
This is usually a dictionary containing data used to
reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="avalanche.benchmarks.NIScenario.classes_in_experience">
<em class="property"><span class="pre">property</span> </em><code class="sig-name descname"><span class="pre">classes_in_experience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Set</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><a class="headerlink" href="#avalanche.benchmarks.NIScenario.classes_in_experience" title="Permalink to this definition">¶</a></dt>
<dd><p>A list that, for each experience (identified by its index/ID),
stores a set of the (optionally remapped) IDs of classes of patterns
assigned to that experience.</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.NIScenario.get_reproducibility_data">
<code class="sig-name descname"><span class="pre">get_reproducibility_data</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span> &#x2192; <span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_instances/ni_scenario/#NIScenario.get_reproducibility_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NIScenario.get_reproducibility_data" title="Permalink to this definition">¶</a></dt>
<dd><p>Gets the data needed to reproduce this experiment.</p>
<p>This data can be stored using the pickle module or some other mechanism.
It can then be loaded by passing it as the <code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code>
parameter in the constructor.</p>
<p>Child classes should get the reproducibility dictionary from super class
and then merge their custom data before returning it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A dictionary containing the data needed to reproduce the
experiment.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.NIExperience">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">NIExperience</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">origin_stream</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><a class="reference internal" href="#avalanche.benchmarks.GenericScenarioStream" title="avalanche.benchmarks.GenericScenarioStream"><span class="pre">GenericScenarioStream</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.NIExperience" title="avalanche.benchmarks.NIExperience"><span class="pre">NIExperience</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.NIScenario" title="avalanche.benchmarks.NIScenario"><span class="pre">NIScenario</span></a><span class="p"><span class="pre">[</span></span><a class="reference internal" href="#avalanche.benchmarks.TrainSet" title="avalanche.benchmarks.TrainSet"><span class="pre">TrainSet</span></a><span class="p"><span class="pre">,</span> </span><a class="reference internal" href="#avalanche.benchmarks.TestSet" title="avalanche.benchmarks.TestSet"><span class="pre">TestSet</span></a><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">current_experience</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/scenarios/new_instances/ni_scenario/#NIExperience"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.NIExperience" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">GenericExperience[NIScenario[TrainSet,</span> <span class="pre">TestSet],</span> <span class="pre">GenericScenarioStream['NIExperience',</span> <span class="pre">NIScenario[TrainSet,</span> <span class="pre">TestSet]]]</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Generic[TrainSet,</span> <span class="pre">TestSet]</span></code></p>
<p>Defines a “New Instances” experience. It defines fields to obtain the
current dataset and the associated task label. It also keeps a reference
to the stream from which this experience was taken.</p>
<p>Creates a <code class="docutils literal notranslate"><span class="pre">NIExperience</span></code> instance given the stream from this
experience was taken and and the current experience ID.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>origin_stream</strong> – The stream from which this experience was
obtained.</p></li>
<li><p><strong>current_experience</strong> – The current experience ID, as an integer.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.nc_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">nc_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_exp_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">,</span> </span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_ids_from_zero_from_first_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_ids_from_zero_in_each_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">one_dataset_per_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reproducibility_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/generators/scenario_generators/#nc_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.nc_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is the high-level specific scenario generator for the
“New Classes” (NC) case. Given a sequence of train and test datasets creates
the continual stream of data as a series of experiences. Each experience
will contain all the patterns belonging to a certain set of classes and a
class won’t be assigned to more than one experience.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">task_labels</span></code> parameter determines if each incremental experience has
an increasing task label or if, at the contrary, a default task label “0”
has to be assigned to all experiences. This can be useful when
differentiating between Single-Incremental-Task and Multi-Task scenarios.</p>
<p>There are other important parameters that can be specified in order to tweak
the behaviour of the resulting scenario. Please take a few minutes to read
and understand them as they may save you a lot of work.</p>
<p>This generator features a integrated reproducibility mechanism that allows
the user to store and later re-load a scenario. For more info see the
<code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – A list of training datasets, or a single dataset.</p></li>
<li><p><strong>test_dataset</strong> – A list of test datasets, or a single test dataset.</p></li>
<li><p><strong>n_experiences</strong> – The number of incremental experience. This is not used
when using multiple train/test datasets with the <code class="docutils literal notranslate"><span class="pre">one_dataset_per_exp</span></code>
parameter set to True.</p></li>
<li><p><strong>task_labels</strong> – If True, each experience will have an ascending task
label. If False, the task label will be 0 for all the experiences.</p></li>
<li><p><strong>shuffle</strong> – If True, the class (or experience) order will be shuffled.
Defaults to True.</p></li>
<li><p><strong>seed</strong> – If <code class="docutils literal notranslate"><span class="pre">shuffle</span></code> is True and seed is not None, the class (or
experience) order will be shuffled according to the seed. When None, the
current PyTorch random number generator state will be used. Defaults to
None.</p></li>
<li><p><strong>fixed_class_order</strong> – If not None, the class order to use (overrides
the shuffle argument). Very useful for enhancing reproducibility.
Defaults to None.</p></li>
<li><p><strong>per_exp_classes</strong> – Is not None, a dictionary whose keys are
(0-indexed) experience IDs and their values are the number of classes
to include in the respective experiences. The dictionary doesn’t
have to contain a key for each experience! All the remaining experiences
will contain an equal amount of the remaining classes. The
remaining number of classes must be divisible without remainder
by the remaining number of experiences. For instance,
if you want to include 50 classes in the first experience
while equally distributing remaining classes across remaining
experiences, just pass the “{0: 50}” dictionary as the
per_experience_classes parameter. Defaults to None.</p></li>
<li><p><strong>class_ids_from_zero_from_first_exp</strong> – If True, original class IDs
will be remapped so that they will appear as having an ascending
order. For instance, if the resulting class order after shuffling
(or defined by fixed_class_order) is [23, 34, 11, 7, 6, …] and
class_ids_from_zero_from_first_exp is True, then all the patterns
belonging to class 23 will appear as belonging to class “0”,
class “34” will be mapped to “1”, class “11” to “2” and so on.
This is very useful when drawing confusion matrices and when dealing
with algorithms with dynamic head expansion. Defaults to False.
Mutually exclusive with the <code class="docutils literal notranslate"><span class="pre">class_ids_from_zero_in_each_exp</span></code>
parameter.</p></li>
<li><p><strong>class_ids_from_zero_in_each_exp</strong> – If True, original class IDs
will be mapped to range [0, n_classes_in_exp) for each experience.
Defaults to False. Mutually exclusive with the
<code class="docutils literal notranslate"><span class="pre">class_ids_from_zero_from_first_exp</span></code> parameter.</p></li>
<li><p><strong>one_dataset_per_exp</strong> – available only when multiple train-test
datasets are provided. If True, each dataset will be treated as a
experience. Mutually exclusive with the <code class="docutils literal notranslate"><span class="pre">per_experience_classes</span></code> and
<code class="docutils literal notranslate"><span class="pre">fixed_class_order</span></code> parameters. Overrides the <code class="docutils literal notranslate"><span class="pre">n_experiences</span></code>
parameter. Defaults to False.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options. This is usually a dictionary containing
data used to reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.ni_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">ni_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">min_class_patterns_in_exp</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_exp_assignment</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reproducibility_data</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Dict</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NIScenario" title="avalanche.benchmarks.NIScenario"><span class="pre">NIScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/generators/scenario_generators/#ni_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.ni_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>This method is the high-level specific scenario generator for the
“New Instances” (NI) case. Given a sequence of train and test datasets
creates the continual stream of data as a series of experiences. Each
experience will contain patterns belonging to the same classes.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">task_labels</span></code> parameter determines if each incremental experience has
an increasing task label or if, at the contrary, a default task label “0”
has to be assigned to all experiences. This can be useful when
differentiating between Single-Incremental-Task and Multi-Task scenarios.</p>
<p>There are other important parameters that can be specified in order to tweak
the behaviour of the resulting scenario. Please take a few minutes to read
and understand them as they may save you a lot of work.</p>
<p>This generator features an integrated reproducibility mechanism that allows
the user to store and later re-load a scenario. For more info see the
<code class="docutils literal notranslate"><span class="pre">reproducibility_data</span></code> parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> – A list of training datasets, or a single dataset.</p></li>
<li><p><strong>test_dataset</strong> – A list of test datasets, or a single test dataset.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences.</p></li>
<li><p><strong>task_labels</strong> – If True, each experience will have an ascending task
label. If False, the task label will be 0 for all the experiences.</p></li>
<li><p><strong>shuffle</strong> – If True, patterns order will be shuffled.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>balance_experiences</strong> – If True, pattern of each class will be equally
spread across all experiences. If False, patterns will be assigned to
experiences in a complete random way. Defaults to False.</p></li>
<li><p><strong>min_class_patterns_in_exp</strong> – The minimum amount of patterns of
every class that must be assigned to every experience. Compatible with
the <code class="docutils literal notranslate"><span class="pre">balance_experiences</span></code> parameter. An exception will be raised if
this constraint can’t be satisfied. Defaults to 0.</p></li>
<li><p><strong>fixed_exp_assignment</strong> – If not None, the pattern assignment
to use. It must be a list with an entry for each experience. Each entry
is a list that contains the indexes of patterns belonging to that
experience. Overrides the <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>, <code class="docutils literal notranslate"><span class="pre">balance_experiences</span></code> and
<code class="docutils literal notranslate"><span class="pre">min_class_patterns_in_exp</span></code> parameters.</p></li>
<li><p><strong>reproducibility_data</strong> – If not None, overrides all the other
scenario definition options, including <code class="docutils literal notranslate"><span class="pre">fixed_exp_assignment</span></code>.
This is usually a dictionary containing data used to
reproduce a specific experiment. One can use the
<code class="docutils literal notranslate"><span class="pre">get_reproducibility_data</span></code> method to get (and even distribute)
the experiment setup so that it can be loaded by passing it as this
parameter. In this way one can be sure that the same specific
experimental setup is being used (for reproducibility purposes).
Beware that, in order to reproduce an experiment, the same train and
test datasets must be used. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NIScenario" title="avalanche.benchmarks.NIScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NIScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.dataset_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">dataset_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_dataset_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportedDataset</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/generators/scenario_generators/#dataset_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.dataset_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of datasets and the respective task
labels. Each training dataset will be considered as a separate training
experience. Contents of the datasets will not be changed, including the
targets.</p>
<p>When loading the datasets from a set of fixed file lists, consider using
the <a class="reference internal" href="#avalanche.benchmarks.filelist_scenario" title="avalanche.benchmarks.filelist_scenario"><code class="xref py py-func docutils literal notranslate"><span class="pre">filelist_scenario()</span></code></a> helper method instead. Also, loading from
a list of paths is supported through the <a class="reference internal" href="#avalanche.benchmarks.paths_scenario" title="avalanche.benchmarks.paths_scenario"><code class="xref py py-func docutils literal notranslate"><span class="pre">paths_scenario()</span></code></a> helper.</p>
<p>In its base form, this function accepts a list of test datasets that must
contain the same amount of datasets of the training list.
Those pairs are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> parameter should be set to True
(see the parameter description for more info).</p>
<p>Beware that pattern transformations must already be included in the
datasets (when needed).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset_list</strong> – A list of training datasets.</p></li>
<li><p><strong>test_dataset_list</strong> – A list of test datasets.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code>
parameter must be list with a single element (the complete test set).
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_dataset_list</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_dataset_list</span></code> must contain the same amount of datasets.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.filelist_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">filelist_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_file_lists</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_file_lists</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span> </span><span class="pre">Path</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/generators/scenario_generators/#filelist_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.filelist_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of filelists and the respective task
labels. A separate dataset will be created for each filelist and each of
those training datasets will be considered a separate training experience.</p>
<p>In its base form, this function accepts a list of filelists for the test
datsets that must contain the same amount of elements of the training list.
Those pairs of datasets are then used to create the “past”, “cumulative”
(a.k.a. growing) and “future” test sets. However, in certain Continual
Learning scenarios only the concept of “complete” test set makes sense. In
that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the
parameter description for more info).</p>
<p>This helper functions is the best shot when loading Caffe-style dataset
based on filelists.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – The root path of the dataset.</p></li>
<li><p><strong>train_file_lists</strong> – A list of filelists describing the
paths of the training patterns for each experience.</p></li>
<li><p><strong>test_file_lists</strong> – A list of filelists describing the
paths of the test patterns for each experience.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code>
parameter must be list with a single element (the complete test set).
Alternatively, can be a plain string or <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code> object.
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.paths_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">paths_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_list_of_files</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_list_of_files</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">FileAndLabel</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/generators/scenario_generators/#paths_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.paths_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given a list of files and class labels.
A separate dataset will be created for each list and each of
those training datasets will be considered a separate training experience.</p>
<p>This is very similar to <cite>filelist_scenario</cite>, with the main difference being
that <cite>filelist_scenario</cite> accepts, for each experience, a file list formatted
in Caffe-style. On the contrary, this accepts a list of tuples where each
tuple contains two elements: the full path to the pattern and its label.
Optionally, the tuple may contain a third element describing the bounding
box of the element to crop. This last bounding box may be useful when trying
to extract the part of the image depicting the desired element.</p>
<p>In its base form, this function accepts a list of lists of tuples for the
test datsets that must contain the same amount of lists of the training
list. Those pairs of datasets are then used to create the “past”,
“cumulative” (a.k.a. growing) and “future” test sets. However, in certain
Continual Learning scenarios only the concept of “complete” test set makes
sense. In that case, the <code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True
(see the parameter description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_list_of_files</strong> – A list of lists. Each list describes the paths
and labels of patterns to include in that training experience as tuples.
Each tuple must contain two elements: the full path to the pattern
and its class label. Optionally, the tuple may contain a third element
describing the bounding box to use for cropping (top, left, height,
width).</p></li>
<li><p><strong>test_list_of_files</strong> – A list of lists. Each list describes the paths
and labels of patterns to include in that test experience as tuples.
Each tuple must contain two elements: the full path to the pattern
and its class label. Optionally, the tuple may contain a third element
describing the bounding box to use for cropping (top, left, height,
width).</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code>
parameter must be list with a single element (the complete test set).
Alternatively, can be a plain string or <code class="xref py py-class docutils literal notranslate"><span class="pre">Path</span></code> object.
Defaults to False, which means that <code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.tensor_scenario">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">tensor_scenario</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_data_x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_data_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportsInt</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_data_x</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_data_y</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">Any</span><span class="p"><span class="pre">,</span> </span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">SupportsInt</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">task_labels</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">complete_test_set_only</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><span class="pre">GenericCLScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/generators/scenario_generators/#tensor_scenario"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.tensor_scenario" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a generic scenario given lists of Tensors and the respective task
labels. A separate dataset will be created from each Tensor pair (x + y)
and each of those training datasets will be considered a separate
training experience. Contents of the datasets will not be changed, including
the targets. Using this helper function is the lower level way to create a
Continual Learning scenario. When possible, consider using higher level
helpers.</p>
<p>In its base form, the test lists must contain the same amount of elements of
the training lists. Those pairs of datasets are then used to create the
“past”, “cumulative” (a.k.a. growing) and “future” test sets.
However, in certain Continual Learning scenarios only the concept of
“complete” test set makes sense. In that case, the
<code class="docutils literal notranslate"><span class="pre">complete_test_set_only</span></code> should be set to True (see the parameter
description for more info).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_data_x</strong> – A list of Tensors (one per experience) containing the
patterns of the training sets.</p></li>
<li><p><strong>train_data_y</strong> – A list of Tensors or int lists containing the
labels of the patterns of the training sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code>.</p></li>
<li><p><strong>test_data_x</strong> – A Tensor or a list of Tensors (one per experience)
containing the patterns of the test sets.</p></li>
<li><p><strong>test_data_y</strong> – A Tensor or a list of Tensors or int lists containing
the labels of the patterns of the test sets. Must contain the same
number of elements of <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code>.</p></li>
<li><p><strong>task_labels</strong> – A list of task labels. Must contain the same amount of
elements of the <code class="docutils literal notranslate"><span class="pre">train_datasets_x</span></code> parameter. For
Single-Incremental-Task (a.k.a. Task-Free) scenarios, this is usually
a list of zeros. For Multi Task scenario, this is usually a list of
ascending task labels (starting from 0).</p></li>
<li><p><strong>complete_test_set_only</strong> – If True, only the complete test set will
be returned by the scenario. This means that the <code class="docutils literal notranslate"><span class="pre">test_datasets_x</span></code> and
<code class="docutils literal notranslate"><span class="pre">test_datasets_y</span></code> parameters must be lists with a single element
(the complete test set). Defaults to False, which means that
<code class="docutils literal notranslate"><span class="pre">train_file_lists</span></code> and <code class="docutils literal notranslate"><span class="pre">test_file_lists</span></code> must contain the same
amount of filelists paths.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>train_target_transform</strong> – The transformation to apply to training
patterns targets. Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_target_transform</strong> – The transformation to apply to test
patterns targets. Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.CORe50">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">CORe50</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">expanduser('~')</span> <span class="pre">+</span> <span class="pre">'/.avalanche/data/core50/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scenario</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'nicv2_391'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">run</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/core50/#CORe50"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.CORe50" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario for CORe50.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>This generator can be used to obtain the NI, NC, NIC and NICv2-* scenarios.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The task label “0” will be assigned to each experience.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Path indicating where to store the dataset and related
metadata. By default they will be stored in
“~/.avalanche/datasets/core50/data/”.</p></li>
<li><p><strong>scenario</strong> – CORe50 main scenario. It can be chosen between ‘ni’, ‘nc’,
‘nic’, ‘nicv2_79’, ‘nicv2_196’ or ‘nicv2_391.’</p></li>
<li><p><strong>run</strong> – number of run for the scenario. Each run defines a different
ordering. Must be a number between 0 and 9.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a properly initialized <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitCIFAR10">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitCIFAR10</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_exp_with_half_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar10_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar10_eval_transform</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/ccifar10/#SplitCIFAR10"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitCIFAR10" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the CIFAR10 dataset.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences in the current scenario.
The value of this parameter should be a divisor of 10 if
<cite>first_task_with_half_classes</cite> is False, a divisor of 5 otherwise.</p></li>
<li><p><strong>first_exp_with_half_classes</strong> – A boolean value that indicates if a
first pretraining step containing half of the classes should be used.
If it’s True, the first experience will use half of the classes (5 for
cifar10). If this parameter is False, no pretraining step will be
used and the dataset is simply split into a the number of experiences
defined by the parameter n_experiences. Defaults to False.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If not None, the <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default eval transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitCIFAR100">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitCIFAR100</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_exp_with_half_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar100_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar100_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/ccifar100/#SplitCIFAR100"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitCIFAR100" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the CIFAR100 dataset.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of incremental experiences in the current
scenario. The value of this parameter should be a divisor of 100 if
first_task_with_half_classes is False, a divisor of 50 otherwise.</p></li>
<li><p><strong>first_exp_with_half_classes</strong> – A boolean value that indicates if a
first pretraining batch containing half of the classes should be used.
If it’s True, a pretraining experience with half of the classes (50 for
cifar100) is used. If this parameter is False no pretraining task
will be used, and the dataset is simply split into a the number of
experiences defined by the parameter n_experiences. Default to False.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitCIFAR110">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitCIFAR110</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar100_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar100_eval_transform</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/ccifar100/#SplitCIFAR110"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitCIFAR110" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using both the CIFAR100 and CIFAR10 datasets.</p>
<p>If the datasets are not present in the computer, this method will
automatically download and store them in the data folder.</p>
<p>The CIFAR10 dataset is used to create the first experience, while the
remaining <cite>n_experiences-1</cite> experiences will be created from CIFAR100.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator will apply a task label “0” to all experiences.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label (always “0” for this specific
benchmark).</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences for the entire scenario.
The first experience will contain the entire CIFAR10 dataset, while the
other n-1 experiences will be obtained from CIFAR100.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order ONLY for the incremental part, which is based on cifar100. The
classes must be in range 0-99.
If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class order for
the incremental batches on cifar100. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter
will be ignored. Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitCUB200">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitCUB200</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">11</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">classes_first_batch</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shuffle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/ccub200/#SplitCUB200"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitCUB200" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the Cub-200 dataset.</p>
<p>If the dataset is not present in the computer, <strong>this method will NOT be
able automatically download</strong> and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Base path where Cub-200 data is stored.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences in the current scenario.
Defaults to 11.</p></li>
<li><p><strong>classes_first_batch</strong> – Number of classes in the first batch.
Usually this is set to 500. Defaults to 100.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>shuffle</strong> – If true, the class order in the incremental experiences is
randomly shuffled. Default to false.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitFMNIST">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitFMNIST</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">first_batch_with_half_classes</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">bool</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar10_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_cifar10_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/cfashion_mnist/#SplitFMNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitFMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the Fashion MNIST dataset.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences in the current
scenario. If the first experience is a “pretraining” step and it
contains half of the classes. The value of this parameter should be a
divisor of 10 if first_task_with_half_classes if false, a divisor of 5
otherwise.</p></li>
<li><p><strong>first_batch_with_half_classes</strong> – A boolean value that indicates if a
first pretraining batch containing half of the classes should be used.
If it’s True, a pretraining batch with half of the classes (5 for
cifar100) is used. If this parameter is False no pretraining task
will be used, and the dataset is simply split into
a the number of experiences defined by the parameter n_experiences.
Default to False.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitImageNet">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitImageNet</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_exp_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/cimagenet/#SplitImageNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitImageNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the Tiny ImageNet dataset.</p>
<p>If the dataset is not present in the computer, <strong>this method will NOT be
able automatically download</strong> and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Base path where Imagenet data is stored.</p></li>
<li><p><strong>n_experiences</strong> – The number of experiences in the current scenario.</p></li>
<li><p><strong>per_exp_classes</strong> – Is not None, a dictionary whose keys are
(0-indexed) experience IDs and their values are the number of classes
to include in the respective experiences. The dictionary doesn’t
have to contain a key for each experience! All the remaining exps
will contain an equal amount of the remaining classes. The
remaining number of classes must be divisible without remainder
by the remaining number of experiences. For instance,
if you want to include 50 classes in the first experience
while equally distributing remaining classes across remaining
experiences, just pass the “{0: 50}” dictionary as the
per_experience_classes parameter. Defaults to None.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitMNIST">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitMNIST</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_mnist_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_mnist_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/cmnist/#SplitMNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the MNIST dataset.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of incremental experiences in the current
scenario.
The value of this parameter should be a divisor of 10.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.PermutedMNIST">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">PermutedMNIST</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">_default_mnist_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">_default_mnist_eval_transform</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/cmnist/#PermutedMNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.PermutedMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a Permuted MNIST scenario.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>Random pixel permutations are used to permute the MNIST images in
<code class="docutils literal notranslate"><span class="pre">n_experiences</span></code> different manners. This means that each experience is
composed of all the original 10 MNIST classes, but the pixel in the images
are permuted in a different way.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>A progressive task label, starting from “0”, is applied to each experience.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences (tasks) in the current
scenario. It indicates how many different permutations of the MNIST
dataset have to be created.
The value of this parameter should be a divisor of 10.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data
before the random permutation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data
before the random permutation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.RotatedMNIST">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">RotatedMNIST</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotations_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_mnist_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_mnist_eval_transform</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/cmnist/#RotatedMNIST"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.RotatedMNIST" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a Rotated MNIST scenario.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>Random angles are used to rotate the MNIST images in <code class="docutils literal notranslate"><span class="pre">n_experiences</span></code>
different manners. This means that each experience is composed of all the
original 10 MNIST classes, but each image is rotated in a different way.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>A progressive task label, starting from “0”, is applied to each experience.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences (tasks) in the current
scenario. It indicates how many different rotations of the MNIST
dataset have to be created.
The value of this parameter should be a divisor of 10.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>rotations_list</strong> – A list of rotations values in degrees (from -180 to
180) used to define the rotations. The rotation specified in position
0 of the list will be applied to the task 0, the rotation specified in
position 1 will be applied to task 1 and so on.
If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the rotations.
If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data
after the random rotation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data
after the random rotation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitOmniglot">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitOmniglot</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_omniglot_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_omniglot_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/comniglot/#SplitOmniglot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitOmniglot" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the OMNIGLOT dataset.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc.</p>
<p>By default, an equal amount of classes will be assigned to each experience.
OMNIGLOT consists of 1623 classes, which means that the number of
experiences can be 1, 3, 541, 1623.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of incremental experiences in the current
scenario. The value of this parameter should be a divisor of 10.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.PermutedOmniglot">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">PermutedOmniglot</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">_default_omniglot_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Any</span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">_default_omniglot_eval_transform</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/comniglot/#PermutedOmniglot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.PermutedOmniglot" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a Permuted Omniglot scenario.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>Random pixel permutations are used to permute the Omniglot images in
<code class="docutils literal notranslate"><span class="pre">n_experiences</span></code> different manners. This means that each experience is
composed of all the original 1623 Omniglot classes, but the pixel in the
images are permuted in a different way.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>A progressive task label, starting from “0”, is applied to each experience.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences (tasks) in the current
scenario. It indicates how many different permutations of the Omniglot
dataset have to be created.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data
before the random permutation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data
before the random permutation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.RotatedOmniglot">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">RotatedOmniglot</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rotations_list</span></span><span class="p"><span class="pre">:</span></span> <span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Sequence</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span> <span class="o"><span class="pre">=</span></span> <span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_omniglot_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_omniglot_eval_transform</span></span></em><span class="sig-paren">)</span> &#x2192; <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><span class="pre">NCScenario</span></a><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/comniglot/#RotatedOmniglot"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.RotatedOmniglot" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a Rotated Omniglot scenario.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>Random angles are used to rotate the Omniglot images in <code class="docutils literal notranslate"><span class="pre">n_experiences</span></code>
different manners. This means that each experience is
composed of all the original 1623 Omniglot classes, but each image is
rotated in a different way.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>A progressive task label, starting from “0”, is applied to each experience.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences (tasks) in the current
scenario. It indicates how many different rotations of the Omniglot
dataset have to be created.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>rotations_list</strong> – A list of rotations values in degrees (from -180 to
180) used to define the rotations. The rotation specified in position
0 of the list will be applied to the task 0, the rotation specified in
position 1 will be applied to task 1 and so on.
If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the rotations.
If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data
after the random rotation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data
after the random rotation, e.g. a random crop, a normalization or a
concatenation of different transformations (see torchvision.transform
documentation for a comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.SplitTinyImageNet">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">SplitTinyImageNet</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_experiences</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">return_task_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_class_order</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_train_transform</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">_default_eval_transform</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/ctiny_imagenet/#SplitTinyImageNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.SplitTinyImageNet" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario using the Tiny ImageNet dataset.</p>
<p>If the dataset is not present in the computer, this method will
automatically download and store it.</p>
<p>The returned scenario will return experiences containing all patterns of a
subset of classes, which means that each class is only seen “once”.
This is one of the most common scenarios in the Continual Learning
literature. Common names used in literature to describe this kind of
scenario are “Class Incremental”, “New Classes”, etc. By default,
an equal amount of classes will be assigned to each experience.</p>
<p>This generator doesn’t force a choice on the availability of task labels,
a choice that is left to the user (see the <cite>return_task_id</cite> parameter for
more info on task labels).</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_experiences</strong> – The number of experiences in the current scenario.</p></li>
<li><p><strong>return_task_id</strong> – if True, a progressive task id is returned for every
experience. If False, all experiences will have a task ID of 0.</p></li>
<li><p><strong>seed</strong> – A valid int used to initialize the random number generator.
Can be None.</p></li>
<li><p><strong>fixed_class_order</strong> – A list of class IDs used to define the class
order. If None, value of <code class="docutils literal notranslate"><span class="pre">seed</span></code> will be used to define the class
order. If non-None, <code class="docutils literal notranslate"><span class="pre">seed</span></code> parameter will be ignored.
Defaults to None.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default train transformation
will be used.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations).
If no transformation is passed, the default test transformation
will be used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A properly initialized <a class="reference internal" href="#avalanche.benchmarks.NCScenario" title="avalanche.benchmarks.NCScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">NCScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="avalanche.benchmarks.OpenLORIS">
<code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">OpenLORIS</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">expanduser('~')</span> <span class="pre">+</span> <span class="pre">'/.avalanche/data/openloris/'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'clutter'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/classic/openloris/#OpenLORIS"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.OpenLORIS" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a CL scenario for OpenLORIS.</p>
<p>If the dataset is not present in the computer, <strong>this method will NOT be
able automatically download</strong> and store it.</p>
<p>This generator can be used to obtain scenarios based on different “factors”.
Valid factors include ‘clutter’, ‘illumination’, ‘occlusion’, ‘pixel’, or
‘mixture-iros’.</p>
<p>The scenario instance returned by this method will have two fields,
<cite>train_stream</cite> and <cite>test_stream</cite>, which can be iterated to obtain
training and test <a class="reference internal" href="#avalanche.benchmarks.Experience" title="avalanche.benchmarks.Experience"><code class="xref py py-class docutils literal notranslate"><span class="pre">Experience</span></code></a>. Each Experience contains the
<cite>dataset</cite> and the associated task label.</p>
<p>The task label “0” will be assigned to each experience.</p>
<p>The scenario API is quite simple and is uniform across all scenario
generators. It is recommended to check the tutorial of the “benchmark” API,
which contains usage examples ranging from “basic” to “advanced”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> – Base path where OpenLORIS data is stored.</p></li>
<li><p><strong>factor</strong> – OpenLORIS main factors, indicating different environmental
variations. It can be chosen between ‘clutter’, ‘illumination’,
‘occlusion’, ‘pixel’, or ‘mixture-iros’. The first three factors are
included in the ICRA 2020 paper and the last factor (mixture-iros) is
the benchmark setting for IROS 2019 Lifelong robotic vision competition.</p></li>
<li><p><strong>train_transform</strong> – The transformation to apply to the training data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
<li><p><strong>eval_transform</strong> – The transformation to apply to the test data,
e.g. a random crop, a normalization or a concatenation of different
transformations (see torchvision.transform documentation for a
comprehensive list of possible transformations). Defaults to None.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a properly initialized <a class="reference internal" href="#avalanche.benchmarks.GenericCLScenario" title="avalanche.benchmarks.GenericCLScenario"><code class="xref py py-class docutils literal notranslate"><span class="pre">GenericCLScenario</span></code></a> instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="avalanche.benchmarks.Stream51">
<em class="property"><span class="pre">class</span> </em><code class="sig-prename descclassname"><span class="pre">avalanche.benchmarks.</span></code><code class="sig-name descname"><span class="pre">Stream51</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">root</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_transform</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">pil_loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">download</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.data.dataset.Dataset</span></code></p>
<p>Stream-51 Pytorch Dataset</p>
<p>Initialize self.  See help(type(self)) for accurate signature.</p>
<dl class="py method">
<dt id="avalanche.benchmarks.Stream51._instance_ordering">
<code class="sig-name descname"><span class="pre">_instance_ordering</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51._instance_ordering"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51._instance_ordering" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Stream51._class_ordering">
<code class="sig-name descname"><span class="pre">_class_ordering</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51._class_ordering"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51._class_ordering" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Stream51._make_dataset">
<code class="sig-name descname"><span class="pre">_make_dataset</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_list</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ordering</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'class_instance'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">666</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51._make_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51._make_dataset" title="Permalink to this definition">¶</a></dt>
<dd><p>data_list
for train: [class_id, clip_num, video_num, frame_num, bbox, file_loc]
for test: [class_id, bbox, file_loc]</p>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Stream51.__getitem__">
<code class="sig-name descname"><span class="pre">__getitem__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">index</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51.__getitem__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51.__getitem__" title="Permalink to this definition">¶</a></dt>
<dd><dl class="simple">
<dt>Args:</dt><dd><p>index (int): Index</p>
</dd>
<dt>Returns:</dt><dd><p>tuple: (sample, target) where target is class_index of the target
class.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Stream51.__len__">
<code class="sig-name descname"><span class="pre">__len__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51.__len__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51.__len__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt id="avalanche.benchmarks.Stream51.__repr__">
<code class="sig-name descname"><span class="pre">__repr__</span></code><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">self</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../../_modules/avalanche/benchmarks/datasets/stream51/stream51/#Stream51.__repr__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#avalanche.benchmarks.Stream51.__repr__" title="Permalink to this definition">¶</a></dt>
<dd><p>Return repr(self).</p>
</dd></dl>

</dd></dl>

</div>
</div>
</div>


           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, ContinualAI.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>